#@meta {desc: "tiny story trainer config", date: "2025-02-03"}
#@meta {url: "https://colab.research.google.com/drive/1ef-tab5bhkvWmBOObepl1WgJvfvSzn5Q?usp=sharing"}


## Defaults
#
default:
  data_dir: ${default:root_dir}/data/tinystory

lmtask_default:
  lmtask_base_resource: lmtask_llama_tinystory_resource


## Train
#
lmtask_trainer_default:
  trainer_name: 'lmtask_trainer_unsloth'
  source_model: 'meta-llama/Llama-3.1-8B'

lmtask_trainer_unsloth_resource:
  generator_resource: 'instance: lmtask_llama_instruct_resource'

lmtask_trainer_unsloth:
  source: 'instance: lmtask_tinystory_source'

lmtask_trainer_unsloth_training_arguments:
  num_train_epochs: 1

lmtask_tinystory_source:
  class_name: zensols.lmtask.dataset.LoadedTaskDatasetFactory
  source: roneneldan/TinyStories
  load_args:
    split: train[:2500]
  task: 'instance: lmtask_task_tinystory'


## Inference
#
lmtask_llama_tinystory_resource:
  class_name: zensols.lmtask.llama.LlamaGeneratorResource
  model_desc: LlaMA 3.1 8B Instruct trained on the tiny story corpus
  model_id: '${lmtask_trainer_default:checkpoint_dir}/checkpoint-156'
  model_args: 'instance: lmtask_llama_model_args'

lmtask_tinystory_stash:
  class_name: zensols.db.sqlite.SqliteDbStash
  path: 'path: ${default:data_dir}/task/tinystory.sqlite3'

lmtask_tinystory_caching_generator:
  class_name: zensols.lmtask.generate.CachingGenerator
  _delegate: 'alias: lmtask_default:lmtask_base_generator'
  _stash: 'instance: lmtask_tinystory_stash'

lmtask_task_tinystory:
  class_name: zensols.lmtask.generate.GenerateTask
  description: 'trained on the tiny story corpus'
  request_class: 'class: zensols.lmtask.task.TaskRequest'
  response_class: 'class: zensols.lmtask.task.TaskResponse'
  1.condition:
    if: ${lmtask_default:cache}
    then:
      generator: 'instance: lmtask_tinystory_caching_generator'
    else:
      generator: 'alias: lmtask_default:lmtask_base_generator'
  resource: 'instance: lmtask_llama_base_resource'
